
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lesson 05 - Supervised Machine Learning - Artificial Neural Networks &#8212; HEADS LEARN v0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=bd9e20870c6007c4c509"></script>

    <script src="_static/documentation_options.js?v=d3792fb7"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lesson05';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lesson 06 - Ensemble Models - Bagging, Boosting and Reliability" href="lesson06.html" />
    <link rel="prev" title="Lesson 04 - Supervised Machine Learning - Support Vector Machines" href="lesson04.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <header>
  
    <div class="bd-header navbar navbar-expand-lg bd-navbar">
    </div>
  
  </header>

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">HEADS LEARN v0.1 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lesson01.html">Lesson 01 - Your First ML project in R</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson02.html">Lesson 02 - Supervised Machine Learning - Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson03.html">Lesson 03 - Graphical Models - Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson04.html">Lesson 04 - Supervised Machine Learning - Support Vector Machines</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lesson 05 - Supervised Machine Learning - Artificial Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson06.html">Lesson 06 - Ensemble Models - Bagging, Boosting and Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson07.html">Lesson 07 - Unsupervised Machine Learning - Clustering and Association Rules</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson08.html">Lesson 08 - Unsupervised Machine Learning - Data Preprocessing and Anomaly Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson09.html">Lesson 09 - Machine Learning from Data Streams</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson10.html">Lesson 10 - Visual Data Mining</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson11.html">Lesson 11 - Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="lesson12.html">Lesson 12 - Text Mining</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/lesson05.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lesson 05 - Supervised Machine Learning - Artificial Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptrons">Perceptrons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-layered-networks">Multi Layered Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-neural-networks">Artificial Neural Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning">Deep Learning</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="lesson-05-supervised-machine-learning-artificial-neural-networks">
<h1>Lesson 05 - Supervised Machine Learning - Artificial Neural Networks<a class="headerlink" href="#lesson-05-supervised-machine-learning-artificial-neural-networks" title="Link to this heading">#</a></h1>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<section id="perceptrons">
<h3>Perceptrons<a class="headerlink" href="#perceptrons" title="Link to this heading">#</a></h3>
<p>“Classifiers such as the one resulting in the orange line, that compute a linear combination of the input features and return the sign of the response, where the line is given by { x : b0 + b1x1 + b2x2 = 0 }.” Rosenblatt (1958)</p>
<p>“The perceptron uses a vector of real input values, computes a linear combination of those, and generates a value of 1 (if above a certain threshold) or -1 (otherwise).” Mitchell (1997)</p>
<p><img alt="alt text" src="_images/image_5.1.png" /></p>
<p><img alt="alt text" src="_images/image_5.2.png" /></p>
<p>“The perceptron can be used to represent any primitive Boolean function AND, OR, ~AND and ~OR. This ability is extremely important given that all Boolean functions can be represented using these primitives.
Moreover, every Boolean function can be represented with a network of perceptrons with at most two levels.” Mitchell (1997)</p>
<p>“The perceptron learning mechanism looks to choose the weight values  w_0, w_1, …, w_n  so that the output value  (o = +- 1)  is correct for each given instance  (x_1, x_2, …, x_n)”  Mitchell (1997)</p>
<p>“The perceptron learning algorithm tries to find a separating hyperplane by minimizing the distance of misclassified points to the decision boundary.” Rosenblatt (1958)</p>
<p>Start with an admissible weight vector (e.g. random) and iteratively apply the perceptron to the examples, modifying the weights every time an example is misclassified.
At each iteration the weights are updated using the perceptron training rule
<img alt="alt text" src="_images/image_5.3.png" /></p>
<p>The learning rate is usually a very low value and is many times decreased over the iterations.</p>
<p>It can be proved that this learning process converges in a finite number of iterations, with perfect classification of examples, as long as they are linearly separable. Mitchell (1997)</p>
<p>If the classes are linearly separable, it can be shown that the algorithm converges to a separating hyperplane in a finite number of steps. However…</p>
<ul class="simple">
<li><p>Problems:</p>
<ul>
<li><p>When the data are separable, there are many solutions, and which one is found depends on the starting values.</p></li>
<li><p>The “finite” number of steps can be very large.</p></li>
<li><p>When the data are not separable, the algorithm will not converge, and cycles develop; the cycles can be long and therefore hard to detect.</p></li>
</ul>
</li>
</ul>
<p><strong>Perceptron Learning (Δ Rule)</strong></p>
<ul class="simple">
<li><p>What if examples are not linearly separable? Algorithm should converge to the best approximation of the concept described by the examples.</p></li>
<li><p>In order to do so, the delta rule uses gradient descent which is the basis of the Backpropagation algorithm used in networks with several units combined.</p></li>
<li><p>The goal is to minimize the error of misclassified data points, which is proportional to the distance of the misclassified points to the decision boundary.</p></li>
<li><p>The algorithm in fact uses stochastic gradient descent to minimize error.</p></li>
<li><p>That is, instead of computing the sum of the (error-based) gradient contributions of each observation followed by a step in the negative gradient direction, a step is taken after each observation is visited.</p></li>
<li><p>Hence the misclassified observations are visited in some sequence, and the parameters are updated via a multiplicative learning rate.</p></li>
</ul>
<p><img alt="alt text" src="_images/image_5.4.png" /></p>
<p>Given the linear perceptron and quadratic error function, the error surface of possible weight hypotheses will always be a paraboloid with a single local minimum</p>
<p><img alt="alt text" src="_images/image_5.5.png" /></p>
<p>At each iteration, the weight vector is updated in the direction of the negative gradient, until the minimum is reached.
This is done by computing the first derivative according to each component of the weight vector, that is, the gradient of E is
<img alt="alt text" src="_images/image_5.6.png" />
This vector gives the direction that maximizes the gradient, so we want
<img alt="alt text" src="_images/image_5.7.png" />
to maximize the gradient descent</p>
<p>Start with an admissible weight vector (e.g. random) and iteratively apply the perceptron to the all the examples, modifying the weights at each new iteration of the entire data set.
At each iteration the weights are updated using the delta training rule
<img alt="alt text" src="_images/image_5.8.png" />
The learning rate is usually a very low value and is many times decreased over the iterations.</p>
<p>If we write the equation according to each component it becomes clear that the gradient is maximized when each component is changed proportionally to the partial derivative for that component.
At each iteration each weight is updated using the delta training rule
<img alt="alt text" src="_images/image_5.9.png" /></p>
</section>
<section id="multi-layered-networks">
<h3>Multi Layered Networks<a class="headerlink" href="#multi-layered-networks" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Each neuron includes a non-linear activation function, although fully differentiable across the entire domain of the function, instead of the one used in the perceptron.</p></li>
<li><p>The use of a logistic function is biology-motivated given that it tries to take into account the refractory phase of real neurons.</p></li>
<li><p>The network includes one or more layers of hidden neurons, highly connected, that are neither input nor output.</p></li>
<li><p>These will allow the model to learning more complex tasks, expanding the search space and dimensions.</p></li>
</ul>
<p><img alt="alt text" src="_images/image_5.10.png" /></p>
<p><strong>Activation Functions</strong>
Each neuron receiving input from N neurons in the previous layer will output a
transformation of
<img alt="alt text" src="_images/image_5.11.png" /></p>
<p><img alt="alt text" src="_images/image_5.12.png" /></p>
<p><strong>Gradient Descent</strong></p>
<p>Each weight will be updated easily since the derivative of these functions is expressed as a function of its output:
<img alt="alt text" src="_images/image_5.13.png" /></p>
<p><strong>Backpropagation</strong></p>
<p>Since we must consider multiple exit values, we must redefine the error function as the sum of all errors in output neurons:
<img alt="alt text" src="_images/image_5.14.png" /></p>
<p>The problem is that the compound error surface will now have multiple local minima, not necessarily the global minimum.
Changes to the gradient descent are needed…</p>
<p><strong>Momentum</strong></p>
<p>To avoid being stuck in local minima, we add a momentum term which tries to maintain the direction from previous update:
<img alt="alt text" src="_images/image_5.15.png" /></p>
<p>Increasing the speed of adaptation in horizontal areas of the error surface, while preventing strict changes in direction. Mitchell (1997)</p>
<p>“However, the presence of distributed non-linearity and high connectivity disable a sound theoretical interpretation of the model. Also, the use of hidden neurons prevents a good visualization of the learning process.” Haykin (1999)</p>
</section>
<section id="artificial-neural-networks">
<h3>Artificial Neural Networks<a class="headerlink" href="#artificial-neural-networks" title="Link to this heading">#</a></h3>
<p>Learning methods based on artificial neural networks are suitable for problems:</p>
<ul class="simple">
<li><p>Instances are represented by many attribute-value pairs</p></li>
<li><p>The target function may be discrete-valued, real-valued, or a vector of real- or discrete-valued attributes</p></li>
<li><p>The training examples may contain errors</p></li>
<li><p>Long training times are acceptable</p></li>
<li><p>Fast evaluation of the learned target function may be required</p></li>
<li><p>The ability of humans to understand the learned target function is not important</p></li>
</ul>
<p><img alt="alt text" src="_images/image_5.16.png" /></p>
<p><strong>Feed-Forward Neural Networks</strong></p>
<p><img alt="alt text" src="_images/image_5.17.png" /></p>
<p><strong>Feed-Backward Neural Networks</strong></p>
<p><img alt="alt text" src="_images/image_5.18.png" /></p>
</section>
<section id="deep-learning">
<h3>Deep Learning<a class="headerlink" href="#deep-learning" title="Link to this heading">#</a></h3>
<p>“The term deep learning refers to artificial neural networks with complex
multilayers.” Albawi (2017)</p>
<p>To express complex models, deep learning has:</p>
<ul class="simple">
<li><p>more neurons,</p></li>
<li><p>more complex ways of connecting layers,</p></li>
<li><p>more computing power to train,</p></li>
<li><p>automatic feature extraction.
Deep learning methods have been found to be fitting for big data study with remarkable success in speech recognition, computer vision, pattern recognition, recommendation systems, and natural language processing. Nowadays, the innovation of DL in image identification, object detection, image classification, and face identification tasks have great success.
One of the most common deep neural network is the convolutional neural network (CNN).
Liu (2017)</p></li>
</ul>
<p>The major concept of deep learning is learning data representations by increasing the quality of handling the ideas rather than events levels.
Mostly in all levels, a significant amount of quality ideas or abstraction representation at a advance level are known through definition regarding fewer quality ideas or non-representations at the basic levels.
This type of stages of learning, growth or hierarchical process of learning is superb because it can enable a system to fathom complex or multi-complex presentations accurately from raw data.
This superb characteristic is making deep learning applicable to different fields
Abiodun (2018)</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lesson04.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lesson 04 - Supervised Machine Learning - Support Vector Machines</p>
      </div>
    </a>
    <a class="right-next"
       href="lesson06.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lesson 06 - Ensemble Models - Bagging, Boosting and Reliability</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptrons">Perceptrons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-layered-networks">Multi Layered Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-neural-networks">Artificial Neural Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning">Deep Learning</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mariana Canelas-Pais
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Mariana Canelas-Pais.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>